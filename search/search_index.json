{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is the MNE Study Template? The MNE Study Template is a full-flegded processing pipeline for your MEG and EEG data. It operates on data stored according to the Brain Imaging Data Structure (BIDS). The input is your raw data; the Study Template is configured using a simple, human-readable configuration file. When run, it will conduct preprocessing (filtering, artifact rejection), epoching, generation of evoked responses, contrasting of experimental conditions, time-frequency analysis, and source estimation. All intermediate results are saved to disk for later inspection, and an extensive report is generated. Analyses are conducted on individual (per-subject) as well as group level.","title":"Introduction"},{"location":"#what-is-the-mne-study-template","text":"The MNE Study Template is a full-flegded processing pipeline for your MEG and EEG data. It operates on data stored according to the Brain Imaging Data Structure (BIDS). The input is your raw data; the Study Template is configured using a simple, human-readable configuration file. When run, it will conduct preprocessing (filtering, artifact rejection), epoching, generation of evoked responses, contrasting of experimental conditions, time-frequency analysis, and source estimation. All intermediate results are saved to disk for later inspection, and an extensive report is generated. Analyses are conducted on individual (per-subject) as well as group level.","title":"What is the MNE Study Template?"},{"location":"getting_started/","text":"1. Inspect your dataset The Study Template only works with BIDS-formatted raw data. To find out more about BIDS and how to convert your data to the BIDS format, please see the documentation of MNE-BIDS . It is of great importance that the BIDS data are anonymized if you require anonymization, as the Study Template does not allow you to anonymize data. This was a conscious design decision, not a technical limitation per se . If you think this decision should be reconsidered, please get in touch with the developers. faulty channels are marked as \"bad\" in the BIDS dataset. While we do run automated bad channel detection in the Study Template, it is considered good practice to flag obviously problematic channels as such in the BIDS dataset. 2. Adjust the configuration file The Study Template ships with a default configuration file, config.py . You need to create a copy of that configuration file and adjust all parameters that are relevant to your data processing and analysis. Info You should only need to touch the configuration file. None of the scripts should be edited. 3. Run the Study Template Run the full Study Template by invoking python run.py process --steps = all --config = /path/to/your/custom_config.py To only run the sensor-level, source-level, or report-generating steps, run: python run.py process --steps = sensor --config = /path/to/your/custom_config.py # sensor-level python run.py process --steps = source --config = /path/to/your/custom_config.py # source-level python run.py process --steps = report --config = /path/to/your/custom_config.py # generate Reports","title":"Getting Started"},{"location":"getting_started/#1-inspect-your-dataset","text":"The Study Template only works with BIDS-formatted raw data. To find out more about BIDS and how to convert your data to the BIDS format, please see the documentation of MNE-BIDS . It is of great importance that the BIDS data are anonymized if you require anonymization, as the Study Template does not allow you to anonymize data. This was a conscious design decision, not a technical limitation per se . If you think this decision should be reconsidered, please get in touch with the developers. faulty channels are marked as \"bad\" in the BIDS dataset. While we do run automated bad channel detection in the Study Template, it is considered good practice to flag obviously problematic channels as such in the BIDS dataset.","title":"1. Inspect your dataset"},{"location":"getting_started/#2-adjust-the-configuration-file","text":"The Study Template ships with a default configuration file, config.py . You need to create a copy of that configuration file and adjust all parameters that are relevant to your data processing and analysis. Info You should only need to touch the configuration file. None of the scripts should be edited.","title":"2. Adjust the configuration file"},{"location":"getting_started/#3-run-the-study-template","text":"Run the full Study Template by invoking python run.py process --steps = all --config = /path/to/your/custom_config.py To only run the sensor-level, source-level, or report-generating steps, run: python run.py process --steps = sensor --config = /path/to/your/custom_config.py # sensor-level python run.py process --steps = source --config = /path/to/your/custom_config.py # source-level python run.py process --steps = report --config = /path/to/your/custom_config.py # generate Reports","title":"3. Run the Study Template"},{"location":"install/","text":"1. Install MNE-Python First, you need to make sure you have MNE-Python installed and working on your system. See the installation instructions . 2. Install additional dependencies You will also need to install the following additional dependencies: mne-bids to operate on BIDS data coloredlogs for nicer logging output tqdm for progress bars pandas for table creation json_tricks for handling of some analysis output scikit-learn for decoding fire for the command line interface typing_extensions if you're using a Python version older than 3.8 You can install those packages via pip : Python 3.8 and newer pip install mne-bids coloredlogs tqdm pandas scikit-learn json_tricks fire Older Python versions pip install mne-bids coloredlogs tqdm pandas json_tricks scikit-learn fire typing_extension 3. Download the Study Template TODO","title":"Installation"},{"location":"install/#1-install-mne-python","text":"First, you need to make sure you have MNE-Python installed and working on your system. See the installation instructions .","title":"1. Install MNE-Python"},{"location":"install/#2-install-additional-dependencies","text":"You will also need to install the following additional dependencies: mne-bids to operate on BIDS data coloredlogs for nicer logging output tqdm for progress bars pandas for table creation json_tricks for handling of some analysis output scikit-learn for decoding fire for the command line interface typing_extensions if you're using a Python version older than 3.8 You can install those packages via pip : Python 3.8 and newer pip install mne-bids coloredlogs tqdm pandas scikit-learn json_tricks fire Older Python versions pip install mne-bids coloredlogs tqdm pandas json_tricks scikit-learn fire typing_extension","title":"2. Install additional dependencies"},{"location":"install/#3-download-the-study-template","text":"TODO","title":"3. Download the Study Template"},{"location":"settings/","text":"config Default settings for data processing and analysis. Do not edit this file, but instead create a new configuration changing only the settings you need to alter for your specific analysis. acq: Optional [ str ] The BIDS acquisition entity. allow_maxshield: bool To import data that was recorded with Maxshield on before running Maxfilter set this to True . baseline: Optional [ tuple ] Specifies how to baseline-correct the epochs; if None , no baseline correction is applied. Example baseline = ( None , 0 ) # baseline between tmin and 0 bids_root: Optional [ str ] Speficy the BIDS root directory. Pass an empty string or `None to use the value specified in the BIDS_ROOT environment variable instead. Raises an exception if the BIDS root has not been specified. Example bids_root = '/path/to/your/bids_root' # Use this to specify a path here. bids_root = None # Make use of the ``BIDS_ROOT`` environment variable. ch_types: Iterable [ str ] The channel types to consider. Note Currently, MEG and EEG data cannot be processed together. Example # Use EEG channels: ch_types = [ 'eeg' ] # Use magnetometer and gradiometer MEG channels: ch_types = [ 'mag' , 'grad' ] # Currently does not work and will raise an error message: ch_types = [ 'meg' , 'eeg' ] conditions: Iterable [ str ] The condition names to consider. This can either be name of the experimental condition as specified in the BIDS events.tsv file; or the name of condition grouped , if the condition names contain the (MNE-specific) group separator, / . See the Subselecting epochs tutorial for more information. Example conditions = [ 'auditory/left' , 'visual/left' ] conditions = [ 'auditory/left' , 'auditory/right' ] conditions = [ 'auditory' ] # All \"auditory\" conditions (left AND right) conditions = [ 'auditory' , 'visual' ] conditions = [ 'left' , 'right' ] contrasts: Iterable [ tuple ] The conditions to contrast via a subtraction of ERPs / ERFs. Each tuple in the list corresponds to one contrast. The condition names must be specified in conditions above. Pass an empty list to avoid calculation of contrasts. Example Contrast the \"left\" and the \"right\" conditions by calculating left - right at every time point of the evoked responses: conditions = [ 'left' , 'right' ] contrasts = [( 'left' , 'right' )] # Note we pass a tuple inside the list! Contrast the \"left\" and the \"right\" conditions within the \"auditory\" and the \"visual\" modality, and \"auditory\" vs \"visual\" regardless of side: conditions = [ 'auditory/left' , 'auditory/right' , 'visual/left' , 'visual/right' ] contrasts = [( 'auditory/left' , 'auditory/right' ), ( 'visual/left' , 'visual/right' ), ( 'auditory' , 'visual' )] crop: Optional [ tuple ] If tuple, (tmin, tmax) to crop the raw data If None (default), do not crop. data_type: Optional [ str ] The BIDS data type. For MEG recordings, this will usually be 'meg'; and for EEG, 'eeg'. However, if your dataset contains simultaneous recordings of MEG and EEG, stored in a single file, you will typically need to set this to 'meg'. If None , we will assume that the data type matches the channel type. Example The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the EEG data, which is stored inside the MEG files: ch_types = [ 'eeg' ] data_type = 'eeg' The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the gradiometer data: ch_types = [ 'grad' ] data_type = 'meg' # or data_type = None The dataset contains only EEG data: ch_types = [ 'eeg' ] data_type = 'eeg' # or data_type = None daysback: Optional [ int ] Warning This parameter will soon be removed! Anonymization should be done on the BIDS dataset before running the Study Template! If not None , apply a time shift to dates to adjust for limitateions of FIFF files. decim: int Says how much to decimate data at the epochs level. It is typically an alternative to the resample_sfreq parameter that can be used for resampling raw data. 1 means no decimation. Good Practice / Advice Decimation requires to lowpass filtered the data to avoid aliasing. Note that using decimation is much faster than resampling. Example decim = 1 # no decimation decim = 4 # decimate by 4 ie devide sampling frequency by 4 decode: bool Whether to perform decoding (MVPA) on the contrasts specified above as \"contrasts\". MVPA will be performed on the level of individual epochs. decoding_metric: str The metric to use for cross-validation. It can be 'roc_auc' or 'accuracy' or any other metric supported by scikit-learn . With AUC, chance level is the same regardless of class balance. decoding_n_splits: int The number of folds (a.k.a. splits) to use in the cross-validation. depth: Union [ float , dict ] If float (default 0.8), it acts as the depth weighting exponent ( exp ) to use (must be between 0 and 1). None is equivalent to 0, meaning no depth weighting is performed. Can also be a dict containing additional keyword arguments to pass to :func: mne.forward.compute_depth_prior (see docstring for details and defaults). eeg_template_montage: Optional [ str ] In situations where you wish to process EEG data and no individual digitization points (measured channel locations) are available, you can apply a \"template\" montage. This means we will assume the EEG cap was placed either according to an international system like 10/20, or as suggested by the cap manufacturers in their respective manual. Please be aware that the actual cap placement most likely deviated somewhat from the template, and, therefore, source reconstruction may be impaired. If None , do not apply a template montage. If a string, must be the name of a built-in template montage in MNE-Python. You can find an overview of supported template montages at https://mne.tools/stable/generated/mne.channels.make_standard_montage.html Example Do not apply template montage: eeg_template_montage = None Apply 64-channel Biosemi 10/20 template montage: eeg_template_montage = 'biosemi64' exclude_subjects: Iterable [ str ] Specify subjects to exclude from analysis. The MEG empty-room mock-subject is automatically excluded from regular analysis. Good Practice / Advice Keep track of the criteria leading you to exclude a participant (e.g. too many movements, missing blocks, aborted experiment, did not understand the instructions, etc, ...) The emptyroom subject will be excluded automatically. find_flat_channels_meg: bool Auto-detect \"flat\" channels (i.e. those with unusually low variability) and mark them as bad. find_noisy_channels_meg Auto-detect \"noisy\" channels and mark them as bad. fix_stim_artifact: bool Apply interpolation to fix stimulation artifact. Example fix_stim_artifact = False h_freq: float The high-frequency cut-off in the lowpass filtering step. Keep it None if no lowpass filtering should be applied. h_trans_bandwidth: Union [ float , Literal [ 'auto' ]] Specifies the transition bandwidth of the lowpass filter. By default it's 'auto' and uses default mne parameters. ica_algorithm: Literal [ 'picard' , 'fastica' , 'extended_infomax' ] The ICA algorithm to use. ica_ctps_ecg_threshold: float The threshold parameter passed to find_bads_ecg method. ica_decim: Optional [ int ] The decimation parameter to compute ICA. If 5 it means that 1 every 5 sample is used by ICA solver. The higher the faster it is to run but the less data you have to compute a good ICA. Set to 1 or None to not perform any decimation. ica_eog_threshold: float The threshold to use during automated EOG classification. Lower values mean that more ICs will be identified as EOG-related. If too low, the false-alarm rate increases dramatically. ica_l_freq: Optional [ float ] The cutoff frequency of the high-pass filter to apply before running ICA. Using a relatively high cutoff like 1 Hz will remove slow drifts from the data, yielding improved ICA results. Set to None to not apply an additional high-pass filter. Note The filter will be applied to raw data which was already filtered according to the l_freq and h_freq settings. After filtering, the data will be epoched, and the epochs will be submitted to ICA. ica_max_iterations: int Maximum number of iterations to decompose the data into independent components. A low number means to finish earlier, but the consequence is that the algorithm may not have finished converging. To ensure convergence, pick a high number here (e.g. 3000); yet the algorithm will terminate as soon as it determines that is has successfully converged, and not necessarily exhaust the maximum number of iterations. Note that the default of 200 seems to be sufficient for Picard in many datasets, because it converges quicker than the other algorithms; but e.g. for FastICA, this limit may be too low to achieve convergence. ica_n_components: Union [ float , int ] MNE conducts ICA as a sort of a two-step procedure: First, a PCA is run on the data (trying to exclude zero-valued components in rank-deficient data); and in the second step, the principal componenets are passed to the actual ICA. You can select how many of the total principal components to pass to ICA \u2013 it can be all or just a subset. This determines how many independent components to fit, and can be controlled via this setting. If int, specifies the number of principal components that are passed to the ICA algorithm, which will be the number of independent components to fit. It must not be greater than the rank of your data (which is typically the number of channels, but may be less in some cases). If float between 0 and 1, all principal components with cumulative explained variance less than the value specified here will be passed to ICA. If None , all principal components will be used. This setting may drastically alter the time required to compute ICA. interactive: bool If True, the scripts will provide some interactive elements, such as figures. If running the scripts from a notebook or Spyder, run %matplotlib qt in the command line to open the figures in a separate window. interpolate_bads_grand_average: bool Interpolate bad sensors in each dataset before calculating the grand average. This parameter is passed to the mne.grand_average function via the keyword argument interpolate_bads . It requires to have channel locations set. Example interpolate_bads_grand_average = True inverse_method: Literal [ 'MNE' , 'dSPM' , 'sLORETA' , 'eLORETA' ] Use minimum norm, dSPM (default), sLORETA, or eLORETA to calculate the inverse solution. l_freq: float The low-frequency cut-off in the highpass filtering step. Keep it None if no highpass filtering should be applied. l_trans_bandwidth: Union [ float , Literal [ 'auto' ]] Specifies the transition bandwidth of the highpass filter. By default it's 'auto' and uses default mne parameters. log_level: Literal [ 'info' , 'error' ] Set the Study Template logging verbosity. loose: Union [ float , Literal [ 'auto' ]] Value that weights the source variances of the dipole components that are parallel (tangential) to the cortical surface. If loose is 0 then the solution is computed with fixed orientation, and fixed must be True or \"auto\". If loose is 1, it corresponds to free orientations. The default value ('auto') is set to 0.2 for surface-oriented source space and set to 1.0 for volumetric, discrete, or mixed source spaces, unless fixed is True in which case the value 0. is used. mf_head_origin mf_head_origin : array-like, shape (3,) | 'auto' Origin of internal and external multipolar moment space in meters. If 'auto', it will be estimated from headshape points. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually. Example mf_head_origin = 'auto' mf_reference_run: Optional [ str ] Despite all possible care to avoid movements in the MEG, the participant will likely slowly drift down from the Dewar or slightly shift the head around in the course of the recording session. Hence, to take this into account, we are realigning all data to a single position. For this, you need to define a reference run (typically the one in the middle of the recording session). Which run to take as the reference for adjusting the head position of all runs. If None , pick the first run. Example mf_reference_run = '01' # Use run \"01\" mf_st_duration: Optional [ float ] There are two kinds of maxfiltering: SSS and tSSS [SSS = signal space separation ; tSSS = temporal signal space separation] (Taulu et al, 2004): http://cds.cern.ch/record/709081/files/0401166.pdf If not None, apply spatiotemporal SSS (tSSS) with specified buffer duration (in seconds). MaxFilter\u2122's default is 10.0 seconds in v2.2. Spatiotemporal SSS acts as implicitly as a high-pass filter where the cut-off frequency is 1/st_dur Hz. For this (and other) reasons, longer buffers are generally better as long as your system can handle the higher memory usage. To ensure that each window is processed identically, choose a buffer length that divides evenly into your data. Any data at the trailing edge that doesn't fit evenly into a whole buffer window will be lumped into the previous buffer. Good Practice / Advice If you are interested in low frequency activity (<0.1Hz), avoid using tSSS and set mf_st_duration to None . If you are interested in low frequency above 0.1 Hz, you can use the default mf_st_duration to 10 s, meaning it acts like a 0.1 Hz high-pass filter. Example mf_st_duration = None mf_st_duration = 10. # to apply tSSS with 0.1Hz highpass filter. mindist: float Exclude points closer than this distance (mm) to the bounding surface. mne_log_level: Literal [ 'info' , 'error' ] Set the MNE-Python logging verbosity. n_boot: int The number of bootstrap resamples when estimating the standard error and confidence interval of the mean decoding score. N_JOBS: int Specifies how many subjects you want to process in parallel. noise_cov: Union [ tuple , Literal [ 'emptyroom' ]] Specify how to estimate the noise covariance matrix, which is used in inverse modeling. If a tuple, it takes the form (tmin, tmax) with the time specified in seconds. If the first value of the tuple is None , the considered period starts at the beginning of the epoch. If the second value of the tuple is None , the considered period ends at the end of the epoch. The default, (None, 0) , includes the entire period before the event, which is typically the pre-stimulus period. If emptyroom , the noise covariance matrix will be estimated from an empty-room MEG recording. The empty-room recording will be automatically selected based on recording date and time. Please note that when processing data that contains EEG channels, the noise covariance can ONLY be estimated from the pre-stimulus period. Example Use the period from start of the epoch until 100 ms before the experimental event: noise_cov = ( None , - 0.1 ) Use the time period from the experimental event until the end of the epoch: noise_cov = ( 0 , None ) Use an empty-room recording: noise_cov = 'emptyroom' on_error: Literal [ 'continue' , 'abort' ] Whether to abort processing as soon as an error occurs, or whether to continue with all other processing steps for as long as possible. proc: Optional [ str ] The BIDS processing entity. process_er: bool Whether to apply the same pre-processing steps to the empty-room data as to the experimental data (up until including frequency filtering). This is required if you wish to use the empty-room recording to estimate noise covariance (via noise_cov='emptyroom' ). The empty-room recording corresponding to the processed experimental data will be retrieved automatically. random_state: Optional [ int ] To specify the seed or state of the random number generator (RNG). This setting is passed to the ICA algorithm and to the decoding function, ensuring reproducible results. Set to None to avoid setting the RNG to a defined state. rec: Optional [ str ] The BIDS recording entity. reject: Optional [ dict ] The rejection limits to mark epochs as bads. This allows to remove strong transient artifacts. If you want to reject and retrieve blinks or ECG artifacts later, e.g. with ICA, don't specify a value for the EOG and ECG channels, respectively (see examples below). Pass None to avoid automated epoch rejection based on amplitude. Note These numbers tend to vary between subjects.. You might want to consider using the autoreject method by Jas et al. 2018. See https://autoreject.github.io Example reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 , 'eog' : 150e-6 } reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 , 'eeg' : 200e-6 } reject = None rename_events: dict A dictionary specifying which events in the BIDS dataset to rename upon loading, and before processing begins. Pass an empty dictionary to not perform any renaming. Example Rename audio_left in the BIDS dataset to audio/left in the pipeline: rename_events = { 'audio_left' : 'audio/left' } resample_sfreq: Optional [ float ] Specifies at which sampling frequency the data should be resampled. If None then no resampling will be done. Example resample_sfreq = None # no resampling resample_sfreq = 500 # resample to 500Hz runs: Union [ Iterable , Literal [ 'all' ]] The runs to process. sessions: Union [ Iterable , Literal [ 'all' ]] The sessions to process. shortest_event: int Minimum number of samples an event must last. If the duration is less than this an exception will be raised. smooth: Optional [ int ] Number of iterations for the smoothing of the surface data. If None, smooth is automatically defined to fill the surface with non-zero values. The default is spacing=None. space: Optional [ str ] The BIDS space entity. spacing: str The spacing to use. Can be 'ico#' for a recursively subdivided icosahedron, 'oct#' for a recursively subdivided octahedron, 'all' for all points, or an integer to use appoximate distance-based spacing (in mm). stim_artifact_tmax: float End time of the interpolation window in seconds. Example stim_artifact_tmax = 0.01 # up to 10ms post-stimulation stim_artifact_tmin: float Start time of the interpolation window in seconds. Example stim_artifact_tmin = 0. # on stim onset study_name: str Specify the name of your study. It will be used to populate filenames for saving the analysis results. Example study_name = 'my-study' subjects: Union [ Iterable [ str ], Literal [ 'all' ]] Subjects to analyze. If 'all' , include all subjects. To only include a subset of subjects, pass a list of their identifiers. Even if you plan on analyzing only a single subject, pass their identifier as a list. Please note that if you intend to EXCLUDE only a few subjects, you should consider setting subjects = 'all' and adding the identifiers of the excluded subjects to exclude_subjects (see next section). Example subjects = 'all' # Include all subjects. subjects = [ '05' ] # Only include subject 05. subjects = [ '01' , '02' ] # Only include subjects 01 and 02. subjects_dir: Optional [ str ] Path to the directory that contains the MRI data files and their derivativesfor all subjects. Specifically, the subjects_dir is the $SUBJECTS_DIR used by the Freesurfer software. If None , will use 'bids_root/derivatives/freesurfer/subjects' . task: str The task to process. time_frequency_conditions: Iterable [ str ] The conditions to compute time-frequency decomposition on. Example time_frequency_conditions = [ 'left' , 'right' ] tmax: float Example tmax = 0.5 # take 500ms after event onset. tmin The beginning of an epoch, relative to the respective event, in seconds. Example tmin = - 0.2 # take 200ms before event onset. use_ica: bool Whether independent component analysis should be used or not. use_maxwell_filter: bool Whether or not to use Maxwell filtering to preprocess the data. Warning If the data were recorded with internal active compensation (MaxShield), they need to be run through Maxwell filter to avoid distortions. Bad channels need to be set through BIDS channels.tsv and / or via the find_flat_channels_meg and find_noisy_channels_meg options above before applying Maxwell filter. use_ssp: bool Whether signal-space projection should be used or not.","title":"Configuration Options"},{"location":"settings/#config","text":"Default settings for data processing and analysis. Do not edit this file, but instead create a new configuration changing only the settings you need to alter for your specific analysis.","title":"config"},{"location":"settings/#config.acq","text":"The BIDS acquisition entity.","title":"acq"},{"location":"settings/#config.allow_maxshield","text":"To import data that was recorded with Maxshield on before running Maxfilter set this to True .","title":"allow_maxshield"},{"location":"settings/#config.baseline","text":"Specifies how to baseline-correct the epochs; if None , no baseline correction is applied. Example baseline = ( None , 0 ) # baseline between tmin and 0","title":"baseline"},{"location":"settings/#config.bids_root","text":"Speficy the BIDS root directory. Pass an empty string or `None to use the value specified in the BIDS_ROOT environment variable instead. Raises an exception if the BIDS root has not been specified. Example bids_root = '/path/to/your/bids_root' # Use this to specify a path here. bids_root = None # Make use of the ``BIDS_ROOT`` environment variable.","title":"bids_root"},{"location":"settings/#config.ch_types","text":"The channel types to consider. Note Currently, MEG and EEG data cannot be processed together. Example # Use EEG channels: ch_types = [ 'eeg' ] # Use magnetometer and gradiometer MEG channels: ch_types = [ 'mag' , 'grad' ] # Currently does not work and will raise an error message: ch_types = [ 'meg' , 'eeg' ]","title":"ch_types"},{"location":"settings/#config.conditions","text":"The condition names to consider. This can either be name of the experimental condition as specified in the BIDS events.tsv file; or the name of condition grouped , if the condition names contain the (MNE-specific) group separator, / . See the Subselecting epochs tutorial for more information. Example conditions = [ 'auditory/left' , 'visual/left' ] conditions = [ 'auditory/left' , 'auditory/right' ] conditions = [ 'auditory' ] # All \"auditory\" conditions (left AND right) conditions = [ 'auditory' , 'visual' ] conditions = [ 'left' , 'right' ]","title":"conditions"},{"location":"settings/#config.contrasts","text":"The conditions to contrast via a subtraction of ERPs / ERFs. Each tuple in the list corresponds to one contrast. The condition names must be specified in conditions above. Pass an empty list to avoid calculation of contrasts. Example Contrast the \"left\" and the \"right\" conditions by calculating left - right at every time point of the evoked responses: conditions = [ 'left' , 'right' ] contrasts = [( 'left' , 'right' )] # Note we pass a tuple inside the list! Contrast the \"left\" and the \"right\" conditions within the \"auditory\" and the \"visual\" modality, and \"auditory\" vs \"visual\" regardless of side: conditions = [ 'auditory/left' , 'auditory/right' , 'visual/left' , 'visual/right' ] contrasts = [( 'auditory/left' , 'auditory/right' ), ( 'visual/left' , 'visual/right' ), ( 'auditory' , 'visual' )]","title":"contrasts"},{"location":"settings/#config.crop","text":"If tuple, (tmin, tmax) to crop the raw data If None (default), do not crop.","title":"crop"},{"location":"settings/#config.data_type","text":"The BIDS data type. For MEG recordings, this will usually be 'meg'; and for EEG, 'eeg'. However, if your dataset contains simultaneous recordings of MEG and EEG, stored in a single file, you will typically need to set this to 'meg'. If None , we will assume that the data type matches the channel type. Example The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the EEG data, which is stored inside the MEG files: ch_types = [ 'eeg' ] data_type = 'eeg' The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the gradiometer data: ch_types = [ 'grad' ] data_type = 'meg' # or data_type = None The dataset contains only EEG data: ch_types = [ 'eeg' ] data_type = 'eeg' # or data_type = None","title":"data_type"},{"location":"settings/#config.daysback","text":"Warning This parameter will soon be removed! Anonymization should be done on the BIDS dataset before running the Study Template! If not None , apply a time shift to dates to adjust for limitateions of FIFF files.","title":"daysback"},{"location":"settings/#config.decim","text":"Says how much to decimate data at the epochs level. It is typically an alternative to the resample_sfreq parameter that can be used for resampling raw data. 1 means no decimation. Good Practice / Advice Decimation requires to lowpass filtered the data to avoid aliasing. Note that using decimation is much faster than resampling. Example decim = 1 # no decimation decim = 4 # decimate by 4 ie devide sampling frequency by 4","title":"decim"},{"location":"settings/#config.decode","text":"Whether to perform decoding (MVPA) on the contrasts specified above as \"contrasts\". MVPA will be performed on the level of individual epochs.","title":"decode"},{"location":"settings/#config.decoding_metric","text":"The metric to use for cross-validation. It can be 'roc_auc' or 'accuracy' or any other metric supported by scikit-learn . With AUC, chance level is the same regardless of class balance.","title":"decoding_metric"},{"location":"settings/#config.decoding_n_splits","text":"The number of folds (a.k.a. splits) to use in the cross-validation.","title":"decoding_n_splits"},{"location":"settings/#config.depth","text":"If float (default 0.8), it acts as the depth weighting exponent ( exp ) to use (must be between 0 and 1). None is equivalent to 0, meaning no depth weighting is performed. Can also be a dict containing additional keyword arguments to pass to :func: mne.forward.compute_depth_prior (see docstring for details and defaults).","title":"depth"},{"location":"settings/#config.eeg_template_montage","text":"In situations where you wish to process EEG data and no individual digitization points (measured channel locations) are available, you can apply a \"template\" montage. This means we will assume the EEG cap was placed either according to an international system like 10/20, or as suggested by the cap manufacturers in their respective manual. Please be aware that the actual cap placement most likely deviated somewhat from the template, and, therefore, source reconstruction may be impaired. If None , do not apply a template montage. If a string, must be the name of a built-in template montage in MNE-Python. You can find an overview of supported template montages at https://mne.tools/stable/generated/mne.channels.make_standard_montage.html Example Do not apply template montage: eeg_template_montage = None Apply 64-channel Biosemi 10/20 template montage: eeg_template_montage = 'biosemi64'","title":"eeg_template_montage"},{"location":"settings/#config.exclude_subjects","text":"Specify subjects to exclude from analysis. The MEG empty-room mock-subject is automatically excluded from regular analysis. Good Practice / Advice Keep track of the criteria leading you to exclude a participant (e.g. too many movements, missing blocks, aborted experiment, did not understand the instructions, etc, ...) The emptyroom subject will be excluded automatically.","title":"exclude_subjects"},{"location":"settings/#config.find_flat_channels_meg","text":"Auto-detect \"flat\" channels (i.e. those with unusually low variability) and mark them as bad.","title":"find_flat_channels_meg"},{"location":"settings/#config.find_noisy_channels_meg","text":"Auto-detect \"noisy\" channels and mark them as bad.","title":"find_noisy_channels_meg"},{"location":"settings/#config.fix_stim_artifact","text":"Apply interpolation to fix stimulation artifact. Example fix_stim_artifact = False","title":"fix_stim_artifact"},{"location":"settings/#config.h_freq","text":"The high-frequency cut-off in the lowpass filtering step. Keep it None if no lowpass filtering should be applied.","title":"h_freq"},{"location":"settings/#config.h_trans_bandwidth","text":"Specifies the transition bandwidth of the lowpass filter. By default it's 'auto' and uses default mne parameters.","title":"h_trans_bandwidth"},{"location":"settings/#config.ica_algorithm","text":"The ICA algorithm to use.","title":"ica_algorithm"},{"location":"settings/#config.ica_ctps_ecg_threshold","text":"The threshold parameter passed to find_bads_ecg method.","title":"ica_ctps_ecg_threshold"},{"location":"settings/#config.ica_decim","text":"The decimation parameter to compute ICA. If 5 it means that 1 every 5 sample is used by ICA solver. The higher the faster it is to run but the less data you have to compute a good ICA. Set to 1 or None to not perform any decimation.","title":"ica_decim"},{"location":"settings/#config.ica_eog_threshold","text":"The threshold to use during automated EOG classification. Lower values mean that more ICs will be identified as EOG-related. If too low, the false-alarm rate increases dramatically.","title":"ica_eog_threshold"},{"location":"settings/#config.ica_l_freq","text":"The cutoff frequency of the high-pass filter to apply before running ICA. Using a relatively high cutoff like 1 Hz will remove slow drifts from the data, yielding improved ICA results. Set to None to not apply an additional high-pass filter. Note The filter will be applied to raw data which was already filtered according to the l_freq and h_freq settings. After filtering, the data will be epoched, and the epochs will be submitted to ICA.","title":"ica_l_freq"},{"location":"settings/#config.ica_max_iterations","text":"Maximum number of iterations to decompose the data into independent components. A low number means to finish earlier, but the consequence is that the algorithm may not have finished converging. To ensure convergence, pick a high number here (e.g. 3000); yet the algorithm will terminate as soon as it determines that is has successfully converged, and not necessarily exhaust the maximum number of iterations. Note that the default of 200 seems to be sufficient for Picard in many datasets, because it converges quicker than the other algorithms; but e.g. for FastICA, this limit may be too low to achieve convergence.","title":"ica_max_iterations"},{"location":"settings/#config.ica_n_components","text":"MNE conducts ICA as a sort of a two-step procedure: First, a PCA is run on the data (trying to exclude zero-valued components in rank-deficient data); and in the second step, the principal componenets are passed to the actual ICA. You can select how many of the total principal components to pass to ICA \u2013 it can be all or just a subset. This determines how many independent components to fit, and can be controlled via this setting. If int, specifies the number of principal components that are passed to the ICA algorithm, which will be the number of independent components to fit. It must not be greater than the rank of your data (which is typically the number of channels, but may be less in some cases). If float between 0 and 1, all principal components with cumulative explained variance less than the value specified here will be passed to ICA. If None , all principal components will be used. This setting may drastically alter the time required to compute ICA.","title":"ica_n_components"},{"location":"settings/#config.interactive","text":"If True, the scripts will provide some interactive elements, such as figures. If running the scripts from a notebook or Spyder, run %matplotlib qt in the command line to open the figures in a separate window.","title":"interactive"},{"location":"settings/#config.interpolate_bads_grand_average","text":"Interpolate bad sensors in each dataset before calculating the grand average. This parameter is passed to the mne.grand_average function via the keyword argument interpolate_bads . It requires to have channel locations set. Example interpolate_bads_grand_average = True","title":"interpolate_bads_grand_average"},{"location":"settings/#config.inverse_method","text":"Use minimum norm, dSPM (default), sLORETA, or eLORETA to calculate the inverse solution.","title":"inverse_method"},{"location":"settings/#config.l_freq","text":"The low-frequency cut-off in the highpass filtering step. Keep it None if no highpass filtering should be applied.","title":"l_freq"},{"location":"settings/#config.l_trans_bandwidth","text":"Specifies the transition bandwidth of the highpass filter. By default it's 'auto' and uses default mne parameters.","title":"l_trans_bandwidth"},{"location":"settings/#config.log_level","text":"Set the Study Template logging verbosity.","title":"log_level"},{"location":"settings/#config.loose","text":"Value that weights the source variances of the dipole components that are parallel (tangential) to the cortical surface. If loose is 0 then the solution is computed with fixed orientation, and fixed must be True or \"auto\". If loose is 1, it corresponds to free orientations. The default value ('auto') is set to 0.2 for surface-oriented source space and set to 1.0 for volumetric, discrete, or mixed source spaces, unless fixed is True in which case the value 0. is used.","title":"loose"},{"location":"settings/#config.mf_head_origin","text":"mf_head_origin : array-like, shape (3,) | 'auto' Origin of internal and external multipolar moment space in meters. If 'auto', it will be estimated from headshape points. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually. Example mf_head_origin = 'auto'","title":"mf_head_origin"},{"location":"settings/#config.mf_reference_run","text":"Despite all possible care to avoid movements in the MEG, the participant will likely slowly drift down from the Dewar or slightly shift the head around in the course of the recording session. Hence, to take this into account, we are realigning all data to a single position. For this, you need to define a reference run (typically the one in the middle of the recording session). Which run to take as the reference for adjusting the head position of all runs. If None , pick the first run. Example mf_reference_run = '01' # Use run \"01\"","title":"mf_reference_run"},{"location":"settings/#config.mf_st_duration","text":"There are two kinds of maxfiltering: SSS and tSSS [SSS = signal space separation ; tSSS = temporal signal space separation] (Taulu et al, 2004): http://cds.cern.ch/record/709081/files/0401166.pdf If not None, apply spatiotemporal SSS (tSSS) with specified buffer duration (in seconds). MaxFilter\u2122's default is 10.0 seconds in v2.2. Spatiotemporal SSS acts as implicitly as a high-pass filter where the cut-off frequency is 1/st_dur Hz. For this (and other) reasons, longer buffers are generally better as long as your system can handle the higher memory usage. To ensure that each window is processed identically, choose a buffer length that divides evenly into your data. Any data at the trailing edge that doesn't fit evenly into a whole buffer window will be lumped into the previous buffer. Good Practice / Advice If you are interested in low frequency activity (<0.1Hz), avoid using tSSS and set mf_st_duration to None . If you are interested in low frequency above 0.1 Hz, you can use the default mf_st_duration to 10 s, meaning it acts like a 0.1 Hz high-pass filter. Example mf_st_duration = None mf_st_duration = 10. # to apply tSSS with 0.1Hz highpass filter.","title":"mf_st_duration"},{"location":"settings/#config.mindist","text":"Exclude points closer than this distance (mm) to the bounding surface.","title":"mindist"},{"location":"settings/#config.mne_log_level","text":"Set the MNE-Python logging verbosity.","title":"mne_log_level"},{"location":"settings/#config.n_boot","text":"The number of bootstrap resamples when estimating the standard error and confidence interval of the mean decoding score.","title":"n_boot"},{"location":"settings/#config.N_JOBS","text":"Specifies how many subjects you want to process in parallel.","title":"N_JOBS"},{"location":"settings/#config.noise_cov","text":"Specify how to estimate the noise covariance matrix, which is used in inverse modeling. If a tuple, it takes the form (tmin, tmax) with the time specified in seconds. If the first value of the tuple is None , the considered period starts at the beginning of the epoch. If the second value of the tuple is None , the considered period ends at the end of the epoch. The default, (None, 0) , includes the entire period before the event, which is typically the pre-stimulus period. If emptyroom , the noise covariance matrix will be estimated from an empty-room MEG recording. The empty-room recording will be automatically selected based on recording date and time. Please note that when processing data that contains EEG channels, the noise covariance can ONLY be estimated from the pre-stimulus period. Example Use the period from start of the epoch until 100 ms before the experimental event: noise_cov = ( None , - 0.1 ) Use the time period from the experimental event until the end of the epoch: noise_cov = ( 0 , None ) Use an empty-room recording: noise_cov = 'emptyroom'","title":"noise_cov"},{"location":"settings/#config.on_error","text":"Whether to abort processing as soon as an error occurs, or whether to continue with all other processing steps for as long as possible.","title":"on_error"},{"location":"settings/#config.proc","text":"The BIDS processing entity.","title":"proc"},{"location":"settings/#config.process_er","text":"Whether to apply the same pre-processing steps to the empty-room data as to the experimental data (up until including frequency filtering). This is required if you wish to use the empty-room recording to estimate noise covariance (via noise_cov='emptyroom' ). The empty-room recording corresponding to the processed experimental data will be retrieved automatically.","title":"process_er"},{"location":"settings/#config.random_state","text":"To specify the seed or state of the random number generator (RNG). This setting is passed to the ICA algorithm and to the decoding function, ensuring reproducible results. Set to None to avoid setting the RNG to a defined state.","title":"random_state"},{"location":"settings/#config.rec","text":"The BIDS recording entity.","title":"rec"},{"location":"settings/#config.reject","text":"The rejection limits to mark epochs as bads. This allows to remove strong transient artifacts. If you want to reject and retrieve blinks or ECG artifacts later, e.g. with ICA, don't specify a value for the EOG and ECG channels, respectively (see examples below). Pass None to avoid automated epoch rejection based on amplitude. Note These numbers tend to vary between subjects.. You might want to consider using the autoreject method by Jas et al. 2018. See https://autoreject.github.io Example reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 , 'eog' : 150e-6 } reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 , 'eeg' : 200e-6 } reject = None","title":"reject"},{"location":"settings/#config.rename_events","text":"A dictionary specifying which events in the BIDS dataset to rename upon loading, and before processing begins. Pass an empty dictionary to not perform any renaming. Example Rename audio_left in the BIDS dataset to audio/left in the pipeline: rename_events = { 'audio_left' : 'audio/left' }","title":"rename_events"},{"location":"settings/#config.resample_sfreq","text":"Specifies at which sampling frequency the data should be resampled. If None then no resampling will be done. Example resample_sfreq = None # no resampling resample_sfreq = 500 # resample to 500Hz","title":"resample_sfreq"},{"location":"settings/#config.runs","text":"The runs to process.","title":"runs"},{"location":"settings/#config.sessions","text":"The sessions to process.","title":"sessions"},{"location":"settings/#config.shortest_event","text":"Minimum number of samples an event must last. If the duration is less than this an exception will be raised.","title":"shortest_event"},{"location":"settings/#config.smooth","text":"Number of iterations for the smoothing of the surface data. If None, smooth is automatically defined to fill the surface with non-zero values. The default is spacing=None.","title":"smooth"},{"location":"settings/#config.space","text":"The BIDS space entity.","title":"space"},{"location":"settings/#config.spacing","text":"The spacing to use. Can be 'ico#' for a recursively subdivided icosahedron, 'oct#' for a recursively subdivided octahedron, 'all' for all points, or an integer to use appoximate distance-based spacing (in mm).","title":"spacing"},{"location":"settings/#config.stim_artifact_tmax","text":"End time of the interpolation window in seconds. Example stim_artifact_tmax = 0.01 # up to 10ms post-stimulation","title":"stim_artifact_tmax"},{"location":"settings/#config.stim_artifact_tmin","text":"Start time of the interpolation window in seconds. Example stim_artifact_tmin = 0. # on stim onset","title":"stim_artifact_tmin"},{"location":"settings/#config.study_name","text":"Specify the name of your study. It will be used to populate filenames for saving the analysis results. Example study_name = 'my-study'","title":"study_name"},{"location":"settings/#config.subjects","text":"Subjects to analyze. If 'all' , include all subjects. To only include a subset of subjects, pass a list of their identifiers. Even if you plan on analyzing only a single subject, pass their identifier as a list. Please note that if you intend to EXCLUDE only a few subjects, you should consider setting subjects = 'all' and adding the identifiers of the excluded subjects to exclude_subjects (see next section). Example subjects = 'all' # Include all subjects. subjects = [ '05' ] # Only include subject 05. subjects = [ '01' , '02' ] # Only include subjects 01 and 02.","title":"subjects"},{"location":"settings/#config.subjects_dir","text":"Path to the directory that contains the MRI data files and their derivativesfor all subjects. Specifically, the subjects_dir is the $SUBJECTS_DIR used by the Freesurfer software. If None , will use 'bids_root/derivatives/freesurfer/subjects' .","title":"subjects_dir"},{"location":"settings/#config.task","text":"The task to process.","title":"task"},{"location":"settings/#config.time_frequency_conditions","text":"The conditions to compute time-frequency decomposition on. Example time_frequency_conditions = [ 'left' , 'right' ]","title":"time_frequency_conditions"},{"location":"settings/#config.tmax","text":"Example tmax = 0.5 # take 500ms after event onset.","title":"tmax"},{"location":"settings/#config.tmin","text":"The beginning of an epoch, relative to the respective event, in seconds. Example tmin = - 0.2 # take 200ms before event onset.","title":"tmin"},{"location":"settings/#config.use_ica","text":"Whether independent component analysis should be used or not.","title":"use_ica"},{"location":"settings/#config.use_maxwell_filter","text":"Whether or not to use Maxwell filtering to preprocess the data. Warning If the data were recorded with internal active compensation (MaxShield), they need to be run through Maxwell filter to avoid distortions. Bad channels need to be set through BIDS channels.tsv and / or via the find_flat_channels_meg and find_noisy_channels_meg options above before applying Maxwell filter.","title":"use_maxwell_filter"},{"location":"settings/#config.use_ssp","text":"Whether signal-space projection should be used or not.","title":"use_ssp"}]}